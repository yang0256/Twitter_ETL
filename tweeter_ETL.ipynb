{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvZwM1mxUTc01bl0NwdIWT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yang0256/Twitter_ETL/blob/main/tweeter_ETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txhjot7XfB4K",
        "outputId": "09144f1e-8dae-4ce2-e0d9-b3add894669b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "0     Brazilian poultry giant BRF is in talks to sel...\n",
            "1     It’s unlikely that China's regional government...\n",
            "2     Bath &amp; Body Works said Dan Loeb’s Third Po...\n",
            "3     \"For buyers brave enough to proceed despite 20...\n",
            "4     Germany is pushing the European Commission to ...\n",
            "                            ...                        \n",
            "95    A Bloomberg investigation traces much of the a...\n",
            "96    RT @BloombergLive: TOMORROW: How has @Delta re...\n",
            "97    The iShares Short Treasury Bond ETF took in al...\n",
            "98    RT @BloombergUK: \"Significant progress has bee...\n",
            "99    Low-cost carrier Wizz Air will suspend all fli...\n",
            "Name: text, Length: 100, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# tweets collector\n",
        "import requests\n",
        "# from datetime import datetime, timedelta\n",
        "# import os\n",
        "# import json\n",
        "import pandas as pd\n",
        "\n",
        "# To set your environment variables in your terminal run the following line:\n",
        "\n",
        "\n",
        "# Set the Bearer Token\n",
        "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAN%2FhlQEAAAAAA3KWaOM4ynnWjSNqd%2BH4ncV6mvU%3DRG5HSsW7lgy9kJakzkn67aBPzmfnAHCELtudRJisaeeNUHlkoj\"\n",
        "# headers = {\"Authorization\": f\"Bearer {bearer_token}\"}\n",
        "# \n",
        "\n",
        "search_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
        "\n",
        "# Optional params: start_time,end_time,since_id,until_id,max_results,next_token,\n",
        "# expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields\n",
        "# query_params = {'query': '(from:twitterdev -is:retweet) OR #twitterdev','tweet.fields': 'author_id'}\n",
        "# query_params = {'query': '(from:business -is:retweet) OR #business','tweet.fields': 'author_id'}\n",
        "query_params = {'query': '(from:OttawaPolice -is:retweet) OR #OttawaPolice','tweet.fields': 'author_id'}\n",
        "\n",
        "#lavienrosye michaeljburry\n",
        "\n",
        "# query_params = {\"query\": \"from:OttawaPolice\", \"max_results\": 100, \"tweet.fields\": \"public_metrics\",  \n",
        "                # \"start_time\":'2023-01-01T00:00:00.000Z', \"end_time\":'2023-02-02T12:00:00.000Z'}\n",
        "\n",
        "# query_params = {\"query\": \"from:OttawaPolice\", \"max_results\": 100, \"tweet.fields\": \"public_metrics\"}\n",
        "query_params = {\"query\": \"from:business\", \"max_results\": 100, \"tweet.fields\": \"public_metrics\"}\n",
        "\n",
        "\n",
        "def bearer_oauth(r):\n",
        "    \"\"\"\n",
        "    Method required by bearer token authentication.\n",
        "    \"\"\"\n",
        "\n",
        "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
        "    r.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
        "    return r\n",
        "\n",
        "def connect_to_endpoint(url, params):\n",
        "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
        "    print(response.status_code)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(response.status_code, response.text)\n",
        "    return response.json()\n",
        "\n",
        "\n",
        "def main():\n",
        "    json_response = connect_to_endpoint(search_url, query_params)\n",
        "    \n",
        "    tweets_df = pd.DataFrame(json_response['data'])\n",
        "    #print(tweets_df[0:1])\n",
        "    print(tweets_df[0:100]['text'])\n",
        "    \n",
        "    tweets_df.to_csv(\"tweets.csv\", index=False)\n",
        "    # tweets_df.info()\n",
        "    # print(json.dumps(json_response, indent=4, sort_keys=True))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('tweets.csv')\n",
        "\n",
        "# View the first few rows of the DataFrame\n",
        "#print(df['text'])"
      ],
      "metadata": {
        "id": "ygttTsi2t9En"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install transformers\n",
        "# Load the FinBERT model\n",
        "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
        "\n",
        "model_name = 'ProsusAI/finbert'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = TFBertForSequenceClassification.from_pretrained(model_name)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShbKQvqMsy_V",
        "outputId": "63e8392a-9c78-449a-f1c4-22d05578a6c3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pro_Positive = 0\n",
        "Pro_Negative = 0\n",
        "# Loop over the values in the \"text\" column and print the length of each one\n",
        "for text in (df['text']):\n",
        "    \n",
        "  # Tokenize your financial texts\n",
        "  text = text\n",
        "  inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "\n",
        "  # Prepare your input\n",
        "  input_ids = inputs[\"input_ids\"]\n",
        "  attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "  # Run inference\n",
        "  outputs = model(input_ids, attention_mask=attention_mask)\n",
        "  scores = outputs[0][0].numpy()\n",
        "  Pro_Positive += scores[1]\n",
        "  Pro_Negative += scores[0]\n",
        "  #print(\"Positive sentiment probability:\", scores[1])\n",
        "  #print(\"Negative sentiment probability:\", scores[0])\n",
        "\n",
        "print(\"Positive sentiment probability:\", Pro_Positive)\n",
        "print(\"Negative sentiment probability:\", Pro_Negative)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb9aPiEuxCvH",
        "outputId": "eb2024f9-2df8-4c7d-a971-c7619b3a1554"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive sentiment probability: 18.382268713787198\n",
            "Negative sentiment probability: 27.545853207819164\n"
          ]
        }
      ]
    }
  ]
}